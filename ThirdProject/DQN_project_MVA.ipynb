{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If train is true, the function implements a greedy algorithm with parameter epsilon, ie: it acts according to the policy learned so far with probability $1-\\epsilon$ and randomly explores other actions with probability $\\epsilon$.\n",
    "\n",
    "$\\textbf{epsilon}$ is necessary to perform exploration, otherwise, the policy would only use the best action so far (best in expectation) and wouldn't try other actions that could be better depending (because of the stochasticity) on the current state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=11 # set small when debugging\n",
    "epochs_test=11 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{board}$ is the array that has the updated reward information, while $\\textbf{position}$ keeps track of the current position of the mouse, it's easier this way to draw the resulting image and perform the calculations without problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "    def learned_act(self, s):\n",
    "        return np.random.randint(0, 4, size=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        ##### FILL IN HERE\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "            \n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "            \n",
    "            # Update the counters\n",
    "            if reward > 0 :\n",
    "                win += reward\n",
    "            else:\n",
    "                lose -= reward\n",
    "                \n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state, action, reward, game_over)\n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 4.5/20.0. Average score (-15.5)\n",
      "Win/lose count 9.5/17.0. Average score (-11.5)\n",
      "Win/lose count 12.0/14.0. Average score (-8.333333333333334)\n",
      "Win/lose count 10.0/11.0. Average score (-6.5)\n",
      "Win/lose count 15.0/20.0. Average score (-6.2)\n",
      "Win/lose count 10.5/11.0. Average score (-5.25)\n",
      "Win/lose count 15.0/10.0. Average score (-3.7857142857142856)\n",
      "Win/lose count 6.0/16.0. Average score (-4.5625)\n",
      "Win/lose count 8.5/13.0. Average score (-4.555555555555555)\n",
      "Win/lose count 7.0/8.0. Average score (-4.2)\n",
      "Win/lose count 12.5/15.0. Average score (-4.045454545454546)\n",
      "Final score: -4.045454545454546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len(self.memory)>self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def random_access(self):\n",
    "        return self.memory[np.random.randint(0,len(self.memory),size=1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            s_, n_s_, a_, r_, game_over_  = self.memory.random_access()\n",
    "            target_q[i] =self.model.predict(s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0]\n",
    "            input_states[i] = s_\n",
    "            \n",
    "            if game_over_:\n",
    "                target_q[i,a_] = r_\n",
    "            else:\n",
    "                target_q[i,a_] = r_  + self.discount*max(self.model.predict(n_s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0])\n",
    "            \n",
    "        # HINT: Clip the target to avoid exploding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        model = Sequential()\n",
    "        model.add(keras.layers.Flatten(input_shape = (5,5,self.n_state,)))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.summary()\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                1224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 100       \n",
      "=================================================================\n",
      "Total params: 1,324\n",
      "Trainable params: 1,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 000/011 | Loss 0.0267 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 001/011 | Loss 0.0163 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 002/011 | Loss 0.1963 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 003/011 | Loss 0.0154 | Win/lose count 0.5/1.0 (-0.5)\n",
      "Epoch 004/011 | Loss 0.0075 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 005/011 | Loss 0.0141 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 006/011 | Loss 0.0998 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 007/011 | Loss 0.0041 | Win/lose count 2.5/5.0 (-2.5)\n",
      "Epoch 008/011 | Loss 0.0076 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 009/011 | Loss 0.0095 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 010/011 | Loss 0.1106 | Win/lose count 1.0/1.0 (0.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(128,(2,2),input_shape=(5,5,self.n_state,), activation='relu'))\n",
    "        model.add(Conv2D(64,(2,2),activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/011 | Loss 0.0142 | Win/lose count 2.0/4.0 (-2.0)\n",
      "Epoch 001/011 | Loss 0.0165 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 002/011 | Loss 0.0136 | Win/lose count 1.5/6.0 (-4.5)\n",
      "Epoch 003/011 | Loss 0.1384 | Win/lose count 0/2.0 (-2.0)\n",
      "Epoch 004/011 | Loss 0.0156 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 005/011 | Loss 0.0030 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 006/011 | Loss 0.0057 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 007/011 | Loss 0.0026 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 008/011 | Loss 0.0047 | Win/lose count 0.5/5.0 (-4.5)\n",
      "Epoch 009/011 | Loss 0.0018 | Win/lose count 2.0/4.0 (-2.0)\n",
      "Epoch 010/011 | Loss 0.0047 | Win/lose count 0.5/5.0 (-4.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train = 11\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 64)          32832     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 2308      \n",
      "=================================================================\n",
      "Total params: 36,292\n",
      "Trainable params: 36,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                1224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 100       \n",
      "=================================================================\n",
      "Total params: 1,324\n",
      "Trainable params: 1,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test of the CNN\n",
      "Win/lose count 1.0/4.0. Average score (-3.0)\n",
      "Win/lose count 1.0/4.0. Average score (-3.0)\n",
      "Win/lose count 1.0/1.0. Average score (-2.0)\n",
      "Win/lose count 1.5/0.0. Average score (-1.125)\n",
      "Win/lose count 2.0/2.0. Average score (-0.9)\n",
      "Win/lose count 1.0/4.0. Average score (-1.25)\n",
      "Win/lose count 1.0/1.0. Average score (-1.0714285714285714)\n",
      "Win/lose count 0/3.0. Average score (-1.3125)\n",
      "Win/lose count 1.0/2.0. Average score (-1.2777777777777777)\n",
      "Win/lose count 2.5/4.0. Average score (-1.3)\n",
      "Win/lose count 2.0/2.0. Average score (-1.1818181818181819)\n",
      "Final score: -1.1818181818181819\n",
      "Test of the FC\n",
      "Win/lose count 2.0/3.0. Average score (-1.0)\n",
      "Win/lose count 0/1.0. Average score (-1.0)\n",
      "Win/lose count 2.0/1.0. Average score (-0.3333333333333333)\n",
      "Win/lose count 2.0/2.0. Average score (-0.25)\n",
      "Win/lose count 2.5/1.0. Average score (0.1)\n",
      "Win/lose count 1.0/2.0. Average score (-0.08333333333333333)\n",
      "Win/lose count 1.5/1.0. Average score (0.0)\n",
      "Win/lose count 1.5/4.0. Average score (-0.3125)\n",
      "Win/lose count 3.5/1.0. Average score (0.0)\n",
      "Win/lose count 1.5/0.0. Average score (0.15)\n",
      "Win/lose count 1.5/5.0. Average score (-0.18181818181818182)\n",
      "Final score: -0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test we do is compare the performances while changing the temperature parameter. I trained the networks for 100 epochs and found out that: \n",
    "- CNN is slower to train but once trained it outperforms FCN for all temperature settings\n",
    "- When we increase the temperature, the gap between the two models gets bigger\n",
    "Another remark about the algorithms is that there isn't enough exploration especially when the temperature parameter is low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        agent.set_epsilon(agent.epsilon*(1-decay_parameter_epsilon))  # Epsilon greedy policy\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size)) #define maluses when going to a previously visited position\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "    def act(self, action,train=False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "        #During the training phase going back to a position where the rat have already been before tends to decrease the \n",
    "        #total reward hence there is this train parameter that we have added (it tries to enforce the exploration)\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1     \n",
    "        \n",
    "        ## In Environment exploring:\n",
    "        # You will have to change n_state to 3 because you will use one more layer!\n",
    "        reward = 0\n",
    "        if train:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "        #At the begining the malus_position array must be setted to zero\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/040 | Loss 0.0145 | Win/lose count 3.5/27.000000000000096 (-23.500000000000096)\n",
      "Epoch 001/040 | Loss 0.0051 | Win/lose count 6.0/20.600000000000012 (-14.600000000000012)\n",
      "Epoch 002/040 | Loss 0.0087 | Win/lose count 7.5/23.000000000000053 (-15.500000000000053)\n",
      "Epoch 003/040 | Loss 0.1782 | Win/lose count 9.5/20.40000000000003 (-10.90000000000003)\n",
      "Epoch 004/040 | Loss 0.0049 | Win/lose count 6.0/29.100000000000115 (-23.100000000000115)\n",
      "Epoch 005/040 | Loss 0.0039 | Win/lose count 4.5/26.90000000000004 (-22.40000000000004)\n",
      "Epoch 006/040 | Loss 0.0048 | Win/lose count 4.5/19.400000000000016 (-14.900000000000016)\n",
      "Epoch 007/040 | Loss 0.2230 | Win/lose count 7.0/23.20000000000002 (-16.20000000000002)\n",
      "Epoch 008/040 | Loss 0.0067 | Win/lose count 2.0/24.600000000000094 (-22.600000000000094)\n",
      "Epoch 009/040 | Loss 0.0037 | Win/lose count 3.5/20.900000000000038 (-17.400000000000038)\n",
      "Epoch 010/040 | Loss 0.0030 | Win/lose count 3.0/21.20000000000002 (-18.20000000000002)\n",
      "Epoch 011/040 | Loss 0.1976 | Win/lose count 2.5/22.500000000000043 (-20.000000000000043)\n",
      "Epoch 012/040 | Loss 0.0063 | Win/lose count 3.5/20.600000000000026 (-17.100000000000026)\n",
      "Epoch 013/040 | Loss 0.0153 | Win/lose count 1.0/21.900000000000027 (-20.900000000000027)\n",
      "Epoch 014/040 | Loss 0.0043 | Win/lose count 1.5/22.90000000000007 (-21.40000000000007)\n",
      "Epoch 015/040 | Loss 0.0022 | Win/lose count 1.5/22.700000000000045 (-21.200000000000045)\n",
      "Epoch 016/040 | Loss 0.0041 | Win/lose count 1.5/23.000000000000053 (-21.500000000000053)\n",
      "Epoch 017/040 | Loss 0.0054 | Win/lose count 3.0/19.0 (-16.0)\n",
      "Epoch 018/040 | Loss 0.2223 | Win/lose count 2.0/21.900000000000052 (-19.900000000000052)\n",
      "Epoch 019/040 | Loss 0.0016 | Win/lose count 1.5/20.10000000000002 (-18.60000000000002)\n",
      "Epoch 020/040 | Loss 0.0035 | Win/lose count 0.5/21.300000000000036 (-20.800000000000036)\n",
      "Epoch 021/040 | Loss 0.0013 | Win/lose count 1.5/21.20000000000002 (-19.70000000000002)\n",
      "Epoch 022/040 | Loss 0.0025 | Win/lose count 1.5/19.1 (-17.6)\n",
      "Epoch 023/040 | Loss 0.2709 | Win/lose count 1.5/19.400000000000006 (-17.900000000000006)\n",
      "Epoch 024/040 | Loss 0.0042 | Win/lose count 1.5/19.400000000000006 (-17.900000000000006)\n",
      "Epoch 025/040 | Loss 0.2486 | Win/lose count 1.5/19.200000000000003 (-17.700000000000003)\n",
      "Epoch 026/040 | Loss 0.0010 | Win/lose count 0.5/21.300000000000036 (-20.800000000000036)\n",
      "Epoch 027/040 | Loss 0.0028 | Win/lose count 1.0/20.400000000000013 (-19.400000000000013)\n",
      "Epoch 028/040 | Loss 0.0060 | Win/lose count 0.5/19.80000000000001 (-19.30000000000001)\n",
      "Epoch 029/040 | Loss 0.0048 | Win/lose count 0/20.400000000000023 (-20.400000000000023)\n",
      "Epoch 030/040 | Loss 0.2541 | Win/lose count 0.5/20.700000000000028 (-20.200000000000028)\n",
      "Epoch 031/040 | Loss 0.0026 | Win/lose count 0.5/19.900000000000013 (-19.400000000000013)\n",
      "Epoch 032/040 | Loss 0.0010 | Win/lose count 0/19.80000000000001 (-19.80000000000001)\n",
      "Epoch 033/040 | Loss 0.2127 | Win/lose count 1.0/20.600000000000023 (-19.600000000000023)\n",
      "Epoch 034/040 | Loss 0.0006 | Win/lose count 0.5/19.900000000000013 (-19.400000000000013)\n",
      "Epoch 035/040 | Loss 0.0007 | Win/lose count 0/19.70000000000001 (-19.70000000000001)\n",
      "Epoch 036/040 | Loss 0.0008 | Win/lose count 0/19.900000000000013 (-19.900000000000013)\n",
      "Epoch 037/040 | Loss 0.0013 | Win/lose count 0.5/19.80000000000001 (-19.30000000000001)\n",
      "Epoch 038/040 | Loss 0.0048 | Win/lose count 0/19.900000000000013 (-19.900000000000013)\n",
      "Epoch 039/040 | Loss 0.2518 | Win/lose count 0/20.000000000000014 (-20.000000000000014)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "epochs_train = 40\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.6, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train,decay_parameter_epsilon=0.1, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 1.0/1.0. Average score (0.0)\n",
      "Win/lose count 0.5/0.0. Average score (0.25)\n",
      "Win/lose count 0.5/0.0. Average score (0.3333333333333333)\n",
      "Win/lose count 0.5/0.0. Average score (0.375)\n",
      "Win/lose count 0.5/0.0. Average score (0.4)\n",
      "Win/lose count 0/1.0. Average score (0.16666666666666666)\n",
      "Win/lose count 0.5/0.0. Average score (0.21428571428571427)\n",
      "Win/lose count 1.5/0.0. Average score (0.375)\n",
      "Win/lose count 0/0.0. Average score (0.3333333333333333)\n",
      "Win/lose count 0.5/0.0. Average score (0.35)\n",
      "Win/lose count 0/0.0. Average score (0.3181818181818182)\n",
      "Final score: 0.3181818181818182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks on the new exploration: At the beginning the exploration policy destroys the efficiency of our algorithm, however, after training is done, we can reach a score of 10 on average for the last epochs with a temperature of 0.3. With the old approach, DQN_CNN couldn't even be stabls. While this might be an improvement, a major downside is the non stability of the training since each different run yields completely different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
